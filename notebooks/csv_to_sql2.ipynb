{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "CSV_PATH = \"../data_acidentes_prf/\"\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "USER = os.getenv(\"user\")\n",
    "PASSWORD = os.getenv(\"password\")\n",
    "SCHEMA = os.getenv(\"schema\")\n",
    "PORT = os.getenv(\"port\")\n",
    "HOST = os.getenv(\"host\")\n",
    "DATABASE = os.getenv(\"database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_delimiter(file_path: str, encoding=\"latin1\") -> str:\n",
    "    with open(file_path, \"r\", encoding=encoding, errors=\"ignore\") as f:\n",
    "        sample = f.read(4096)\n",
    "        sniffer = csv.Sniffer()\n",
    "        return sniffer.sniff(sample).delimiter\n",
    "\n",
    "def files_in_path(path:str) -> list[str]:\n",
    "    return [file for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "\n",
    "def csvs_to_df(files_csvs: list[str]) -> list[pd.DataFrame]:\n",
    "    dataframes = []\n",
    "\n",
    "    for file in files_csvs:\n",
    "        file_path = f\"{CSV_PATH}{file}\"\n",
    "        sep = detect_delimiter(file_path)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                sep=sep,\n",
    "                encoding=\"latin1\",\n",
    "                engine=\"python\",\n",
    "                on_bad_lines=\"skip\",\n",
    "                chunksize=900_000\n",
    "            )\n",
    "\n",
    "            dataframes.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Falha ao ler {file}\")\n",
    "            print(f\"Erro: {e}\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "files = files_in_path(CSV_PATH)\n",
    "dfs = csvs_to_df(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0389f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: fix: function -> normalize_table_name\n",
    "def normalize_table_name(filename: str) -> str:\n",
    "    name = filename.lower().replace(\".csv\", \"\")\n",
    "    return re.sub(r\"[^a-z0-9_]\", \"_\", name)\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"{DATABASE}://{USER}:{PASSWORD}@{HOST}:{PORT}/{SCHEMA}\"\n",
    ")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for file_name, reader in zip(files, dfs):\n",
    "        table_name = normalize_table_name(file_name)\n",
    "        first_chunk = True\n",
    "\n",
    "        print(f\"ðŸ“¥ Importing {file_name} â†’ table {table_name}\")\n",
    "\n",
    "        for df_chunk in reader:\n",
    "            df_chunk.to_sql(\n",
    "                table_name,\n",
    "                conn,\n",
    "                if_exists=\"replace\" if first_chunk else \"append\",\n",
    "                index=False,\n",
    "                method=\"multi\",\n",
    "                chunksize=100_000\n",
    "            )\n",
    "            first_chunk = False\n",
    "        print(f\"âœ… Tabela {table_name} criada com sucesso\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-data-prf-gov (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
